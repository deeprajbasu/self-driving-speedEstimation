{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#import libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# extract frames from mp4 files and return list of frames\n",
    "\n",
    "total_frames = 1000#control how many frames to add\n",
    "\n",
    "\n",
    "def getFrames(vidfile):\n",
    "    vid = cv2.VideoCapture(vidfile)\n",
    "    frames = []\n",
    "    endframe = True\n",
    "    t = 0\n",
    "    while endframe:\n",
    "        if t>total_frames:\n",
    "            break\n",
    "        endframe,frame = vid.read()\n",
    "        #print(frame)\n",
    "        if endframe:\n",
    "            frames.append(frame)\n",
    "            #print(\"processing frame: \",t)\n",
    "            t+=1\n",
    "    return frames\n",
    "\n",
    "#read outpub vals for txtfile and make list    \n",
    "def getSpeed(txtfile):\n",
    "    speeds = []\n",
    "    t=0\n",
    "    with open(txtfile) as f:\n",
    "        for line in f :\n",
    "            if t>total_frames:\n",
    "                break\n",
    "            speed = line.rstrip('\\n')\n",
    "            speed = float(speed)\n",
    "            speeds.append(speed)\n",
    "            #print(\"speed at frame: \",t,\"is: \",speed)\n",
    "            t+=1\n",
    "    return speeds\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#get data from files into lists\n",
    "\n",
    "path_txt = \"data/train.txt\"\n",
    "path_mp4 = \"data/train.mp4\"\n",
    "\n",
    "\n",
    "images_data= getFrames(path_mp4)\n",
    "speed_data = getSpeed(path_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((480, 640, 3), 28.105569)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "images_data[0].shape,speed_data[0]\n",
    "#confirm image and floats in lists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#generate optical flow output with raw data\n",
    "\n",
    "def compute_dense_optical_flow(prev_image, current_image):\n",
    "\n",
    "  #resize images \n",
    "\n",
    "  scale_percent = 20 # percent of original size\n",
    "  width = int(prev_image.shape[1] * scale_percent / 100)\n",
    "  height = int(prev_image.shape[0] * scale_percent / 100)\n",
    "  dim = (width, height)\n",
    "  \n",
    "  # resize image\n",
    "  prev_image = cv2.resize(prev_image, dim, interpolation = cv2.INTER_AREA)\n",
    "  current_image = cv2.resize(current_image, dim, interpolation = cv2.INTER_AREA) \n",
    "\n",
    "\n",
    "\n",
    "  old_shape = current_image.shape\n",
    "  prev_image_gray = cv2.cvtColor(prev_image, cv2.COLOR_BGR2GRAY)\n",
    "  current_image_gray = cv2.cvtColor(current_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "  assert current_image.shape == old_shape\n",
    "  \n",
    "  hsv = np.zeros_like(prev_image)\n",
    "  hsv[..., 1] = 255\n",
    "  flow = None\n",
    "  flow = cv2.calcOpticalFlowFarneback(prev=prev_image_gray,\n",
    "                                      next=current_image_gray, flow=flow,\n",
    "                                      pyr_scale=0.8, levels=15, winsize=5,\n",
    "                                      iterations=10, poly_n=5, poly_sigma=0,\n",
    "                                      flags=10)\n",
    "\n",
    "  mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "  hsv[..., 0] = ang * 180 / np.pi / 2\n",
    "  hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "  return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create optical flow images and list of mean speed\n",
    "#features and labels we will be hitting the model with\n",
    "\n",
    "opticalFlowFrames = []\n",
    "speed_Data_final=[]\n",
    "for i in range(0,len(images_data)-4):#trying to get better optical flow by comparing distant frames,                                                                 #instead of consecutive \n",
    "\n",
    "    image = compute_dense_optical_flow(images_data[i],images_data[i+4])\n",
    "    opticalFlowFrames.append(image)\n",
    "    mean_speed = (speed_data[i] + speed_data[i+1])\n",
    "    label = np.asarray(mean_speed,dtype= np.float32)\n",
    "    speed_Data_final.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see optical flow result\n",
    "img = Image.fromarray(opticalFlowFrames[4], 'RGB')\n",
    "img.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#train and validation split\n",
    "\n",
    "split_ratio = 0.8\n",
    "train_data = opticalFlowFrames[:int(split_ratio*len(opticalFlowFrames))]\n",
    "train_labels = speed_Data_final[:int(split_ratio*len(speed_Data_final))]\n",
    "\n",
    "val_data = opticalFlowFrames[int(split_ratio*len(opticalFlowFrames)):]\n",
    "val_labels = speed_Data_final[int(split_ratio*len(speed_Data_final)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(797, 200)"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "len(train_labels),len(val_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create tensorflow datasets using our features and labels \n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_data,train_labels))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_data,val_labels))\n",
    "\n",
    "#batch up our datasets \n",
    "train_dataset=train_dataset.batch(10)\n",
    "val_dataset=val_dataset.batch(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "#create our model\n"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Conv2D(24,(5,5), strides=2, padding='same',activation='relu',input_shape=(96, 128, 3)))\n",
    "\n",
    "#convolutions\n",
    "model.add(tf.keras.layers.Conv2D(36,(5,5), strides=2, padding='same',activation='relu'))\n",
    "model.add(tf.keras.layers.Conv2D(48,(5,5), strides=2, padding='same',activation='relu'))\n",
    "model.add(tf.keras.layers.Conv2D(64,(3,3), strides=1, padding='same',activation='relu'))\n",
    "model.add(tf.keras.layers.Conv2D(64,(3,3), strides=1, padding='same',activation='relu'))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "#dense layers\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(50, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 48, 64, 24)        1824      \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 24, 32, 36)        21636     \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 12, 16, 48)        43248     \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 12, 16, 64)        27712     \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 12, 16, 64)        36928     \n_________________________________________________________________\nflatten (Flatten)            (None, 12288)             0         \n_________________________________________________________________\ndense (Dense)                (None, 100)               1228900   \n_________________________________________________________________\ndense_1 (Dense)              (None, 50)                5050      \n_________________________________________________________________\ndense_2 (Dense)              (None, 10)                510       \n_________________________________________________________________\ndense_3 (Dense)              (None, 1)                 11        \n=================================================================\nTotal params: 1,365,819\nTrainable params: 1,365,819\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() #observe our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.MSE,\n",
    "              metrics=['MSE'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None, 96, 128, 3), dtype=tf.int32, name=None),\n",
       " TensorSpec(shape=(None,), dtype=tf.float32, name=None))"
      ]
     },
     "metadata": {},
     "execution_count": 211
    }
   ],
   "source": [
    "train_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f6b602dcf98>"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "# load weights if retraining\n",
    "model.load_weights('./checkpoints/1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train for 80 steps, validate for 20 steps\n",
      "Epoch 1/10\n",
      "80/80 [==============================] - 8s 95ms/step - loss: 4.4884 - MSE: 4.4922 - val_loss: 14.7613 - val_MSE: 14.7613\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 6s 70ms/step - loss: 1.4009 - MSE: 1.3824 - val_loss: 24.2879 - val_MSE: 24.2879\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 6s 72ms/step - loss: 1.5200 - MSE: 1.4974 - val_loss: 25.4948 - val_MSE: 25.4948\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 6s 71ms/step - loss: 1.2929 - MSE: 1.2784 - val_loss: 26.3009 - val_MSE: 26.3009\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 6s 72ms/step - loss: 1.2831 - MSE: 1.2748 - val_loss: 26.2670 - val_MSE: 26.2670\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 6s 75ms/step - loss: 1.0081 - MSE: 1.0011 - val_loss: 27.5537 - val_MSE: 27.5537\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 6s 76ms/step - loss: 0.7329 - MSE: 0.7337 - val_loss: 17.9852 - val_MSE: 17.9852\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 6s 74ms/step - loss: 1.4410 - MSE: 1.4429 - val_loss: 16.9821 - val_MSE: 16.9821\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 6s 75ms/step - loss: 1.7795 - MSE: 1.7846 - val_loss: 14.1359 - val_MSE: 14.1359\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 6s 80ms/step - loss: 1.8793 - MSE: 1.8811 - val_loss: 11.2685 - val_MSE: 11.2685\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6b6024fd30>"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=10,validation_data=val_dataset,use_multiprocessing=True,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./checkpoints/3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Keras TensorBoard callback.\n",
    "from datetime import datetime \n",
    "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train for 80 steps, validate for 20 steps\n",
      "Epoch 1/10\n",
      "80/80 [==============================] - 7s 82ms/step - loss: 1.9262 - MSE: 1.9289 - val_loss: 15.3139 - val_MSE: 15.3139\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 6s 79ms/step - loss: 0.7889 - MSE: 0.7886 - val_loss: 15.1308 - val_MSE: 15.1308\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 7s 91ms/step - loss: 2.2867 - MSE: 2.2833 - val_loss: 18.1100 - val_MSE: 18.1100\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 7s 87ms/step - loss: 1.2274 - MSE: 1.2295 - val_loss: 17.7400 - val_MSE: 17.7400\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 6s 76ms/step - loss: 1.6385 - MSE: 1.6432 - val_loss: 10.8958 - val_MSE: 10.8958\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 6s 77ms/step - loss: 1.5265 - MSE: 1.5261 - val_loss: 3.6207 - val_MSE: 3.6207\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 6s 80ms/step - loss: 2.6698 - MSE: 2.6781 - val_loss: 10.4097 - val_MSE: 10.4097\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 6s 81ms/step - loss: 2.5584 - MSE: 2.5638 - val_loss: 7.1546 - val_MSE: 7.1546\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 6s 79ms/step - loss: 2.3737 - MSE: 2.3639 - val_loss: 3.1935 - val_MSE: 3.1935\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 7s 88ms/step - loss: 3.0473 - MSE: 3.0453 - val_loss: 2.8058 - val_MSE: 2.8058\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6a9b6652b0>"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=10,validation_data=val_dataset,use_multiprocessing=True,callbacks=[tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "git filter-branch --index-filter 'git rm -r --cached --ignore-unmatch <data>' HEAD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.2.1 at http://localhost:6007/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.12 64-bit ('comma': conda)",
   "language": "python",
   "name": "python361264bitcommacondab076faaeeb984dccbef60de7201bf3cf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}